import pandas as pd

# import mysql.connector

# # Define the database connection parameters
# host = 'localhost'      # Replace with your MySQL server hostname or IP address
# database = 'your_database_name'  # Replace with the name of your database
# user = 'your_username'  # Replace with your MySQL username
# password = 'your_password'  # Replace with your MySQL password

# # Connect to the MySQL database
# try:
#     conn = mysql.connector.connect(
#         host=host,
#         database=database,
#         user=user,
#         password=password
#     )

#     if conn.is_connected():
#         print(f"Connected to the '{database}' database")

#         # Create a cursor object to execute SQL queries
#         cursor = conn.cursor()

#         # Execute SQL queries using cursor
#         cursor.execute('''CREATE TABLE IF NOT EXISTS users (
#                             id INT AUTO_INCREMENT PRIMARY KEY,
#                             name VARCHAR(255),
#                             age INT
#                         )''')

#         cursor.execute("INSERT INTO users (name, age) VALUES (%s, %s)", ('John', 30))
#         conn.commit()
#         print("Data inserted successfully.")

#         # Close the cursor and connection
#         cursor.close()
#         conn.close()

# except mysql.connector.Error as e:
#     print(f"Error connecting to MySQL: {e}")


data = pd.read_csv(r'C:\Users\Sarthak\Desktop\apparel.csv')
interaction_matrix = pd.pivot_table(data, values='rating', index='user_id', columns='item_id', fill_value=0)

import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout
from tensorflow.keras.models import Model

num_users = len(data['user_id'].unique())
num_items = len(data['item_id'].unique())

user_input = Input(shape=(1,))
item_input = Input(shape=(1,))

user_embedding = Embedding(num_users, 50)(user_input)
item_embedding = Embedding(num_items, 50)(item_input)

user_flatten = Flatten()(user_embedding)
item_flatten = Flatten()(item_embedding)

concat = tf.keras.layers.Concatenate()([user_flatten, item_flatten])

hidden_layer = Dense(128, activation='relu')(concat)
dropout = Dropout(0.2)(hidden_layer)
output_layer = Dense(1, activation='sigmoid')(dropout)

model = Model(inputs=[user_input, item_input], outputs=output_layer)
model.compile(optimizer='adam', loss='mean_squared_error')

from sklearn.model_selection import train_test_split

train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)

train_user_ids = train_data['user_id'].values
train_item_ids = train_data['item_id'].values
train_ratings = train_data['rating'].values

val_user_ids = val_data['user_id'].values
val_item_ids = val_data['item_id'].values
val_ratings = val_data['rating'].values

model.fit([train_user_ids, train_item_ids], train_ratings,
          validation_data=([val_user_ids, val_item_ids], val_ratings),
          batch_size=64, epochs=10)

def get_recommendations(user_id, top_n=5):
    all_item_ids = data['item_id'].unique()
    
    predictions = pd.DataFrame({'item_id': all_item_ids})
    
    predictions['user_id'] = user_id
    
    predictions['predicted_rating'] = model.predict([predictions['user_id'], predictions['item_id']])
    
    top_recommendations = predictions.sort_values(by='predicted_rating', ascending=False).head(top_n)
    
    return top_recommendations

user_id_to_recommend = 'User1'
top_recommendations = get_recommendations(user_id_to_recommend, top_n=5)
print(top_recommendations)
#recommendations are made on the basis of current trends 
